#! /usr/bin/env python
# -*- coding: utf-8 -*
##########################################################################
# NSAp - Copyright (C) CEA, 2018
# Distributed under the terms of the CeCILL-B license, as published by
# the CEA-CNRS-INRIA. Refer to the LICENSE file or to
# http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html for details.
##########################################################################

# System import
import os
import argparse
import textwrap
from argparse import RawTextHelpFormatter
from datetime import datetime
from pprint import pprint

# Package import
from pyconnectome import __version__ as version
from pyconnectome.utils.filetools import parse_graph
from pyconnectome.metrics.dfold import convert_folds
from pyconnectome.metrics.dfold import convert_pits
from pyconnectome.metrics.dfold import sphere_integration

# Third party import
import json
import numpy as np

# Parameters to keep trace
__hopla__ = ["runtime", "inputs", "outputs"]

# Bredala module
try:
    import bredala
    bredala.USE_PROFILER = False
    bredala.register("pyconnectome.utils.filetools",
                     names=["parse_graph"])
    bredala.register("pyconnectome.metrics.dfold",
                     names=["convert_fold", "sphere_integration"])
except:
    pass


# Script documentation
DOC = """
Evaluation of folds features
-----------------------------

Extract features along different folds (e.g : FA) and output a summary of
these features in csv and json files.

Requirements:
    - fold files (.gii) for left and right hemisphere (required).
    - T1 image file (required).
    - scalar image files (e.g FA image file) (required).
    - subject id (required).
    - morphologist graph files (.arg) for left and right hemisphere (required).
    - folds' ids on which to extract features for each hemisphere  :
      if no fold is specified features are extracted on every folds,
      if -1 is specified no fold is extracted (optional).
    - white/grey matter segmentation files for left and right hemisphere
      (optional).

Command example on the HCP data :

For fold features' computation
python pyconnectome_folds_metrics \
    -o $PROJECT/HCP_FOLDS/TEST_OUTPUT \
    -s 101006 \
    -t /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/101006.nii.gz \
    -a $PROJECT/HCP_FOLDS/TEST_OUTPUT/101006/3000/dtifit_FA.nii.gz \
    -F /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/L101006_default_session_auto.data/aims_Tmtktri.gii \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/R101006_default_session_auto.data/aims_Tmtktri.gii \
    -A /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/L101006_default_session_auto.arg \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/R101006_default_session_auto.arg \
    -M /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/Lgrey_white_101006.nii.gz \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/Rgrey_white_101006.nii.gz \
    -L 86 \
    -R 86

For pit features' computation
python pyconnectome_folds_metrics \
    -o $PROJECT/HCP_FOLDS/TEST_OUTPUT \
    -s 101006 \
    -t /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/101006.nii.gz \
    -a $PROJECT/HCP_FOLDS/TEST_OUTPUT/101006/3000/dtifit_FA.nii.gz \
    -M /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/Lgrey_white_101006.nii.gz \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/Rgrey_white_101006.nii.gz \
    -I /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/mesh/surface_analysis/101006_Lwhite_pits.gii \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/mesh/surface_analysis/101006_Rwhite_pits.gii \
    -G /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/mesh/101006_Lwhite.gii \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/mesh/101006_Rwhite.gii

"""


def is_file(filepath):
    """ Check file's existence - argparse 'type' argument.
    """
    if not os.path.isfile(filepath):
        raise argparse.ArgumentError("File does not exist: %s" % filepath)
    return filepath


def is_directory(dirarg):
    """ Type for argparse - checks that directory exists.
    """
    if not os.path.isdir(dirarg):
        raise argparse.ArgumentError(
            "The directory '{0}' does not exist!".format(dirarg))
    return dirarg


# Parse input arguments
def get_cmd_line_args():
    """
    Create a command line argument parser and return a dict mapping
    <argument name> -> <argument value>.
    """
    parser = argparse.ArgumentParser(
        prog="python pyconnectome_get_folds_metrics",
        description=textwrap.dedent(DOC),
        formatter_class=RawTextHelpFormatter)

    # Required arguments
    required = parser.add_argument_group("required arguments")
    required.add_argument(
        "-o", "--outdir",
        type=is_directory, required=True, metavar="<path>",
        help="Directory where to output.")
    required.add_argument(
        "-s", "--subject", type=str, required=True, help="Subject ID.")
    required.add_argument(
        "-t", "--t1",
        type=is_file, required=True, metavar="<path>",
        help="Path to the T1 image file.")
    required.add_argument(
        "-a", "--scalarfile",
        type=is_file, nargs='+', required=True, metavar="<path>",
        help="Path to at least one scalar image file.")

    # Optional argument
    parser.add_argument(
        "-F", "--foldsfile",
        type=is_file, nargs='+', metavar="<path>",
        help="Path to the folds .gii file. The left hemisphere folds file must"
             "be the first input")
    required.add_argument(
        "-A", "--graphfile",
        type=is_file, nargs='+', metavar="<path>",
        help="Path to the morphologist graph file. The left hemisphere graph "
             "file must be the first input")
    parser.add_argument(
        "-L", "--leftfolds",
        type=int, nargs='*',
        help="Selection of left hemisphere folds indexes on which to compute"
             "value (e.g : 94). Not adding this argument will compute the"
             "folds' metrics on every fold and putting this argument to -1"
             "won't compute any value for the hemisphere folds.")
    parser.add_argument(
        "-R", "--rightfolds",
        type=int, nargs='*',
        help="Selection of right hemisphere folds indexes on which to compute"
             "value (e.g : 94). Not adding this argument will compute the"
             "folds' metrics on every fold and putting this argument to -1"
             "won't compute any value for the hemisphere folds.")
    parser.add_argument(
        "-I", "--pitsfiles",
        type=is_file, nargs='*',
        help="Selection of left and right hemisphere pits indexes on which to"
             "compute scalar values. Not adding this argument will compute the"
             "scalars' metrics on folds instead of pits. The left hemisphere"
             "pits indexes must be the first input.")
    parser.add_argument(
        "-G", "--meshfiles",
        type=is_file, nargs='*',
        help="Selection of left and right hemisphere white mesh file. The left"
             "hemisphere white mesh file must be the first input.")
    parser.add_argument(
        "-M", "--wgmfile",
        type=is_file, nargs='*', metavar="<path>",
        help="Path to the white/grey matter segmentation files. The left "
              "hemisphere segmentation file must be the first input")
    parser.add_argument(
        "-V", "--verbose",
        type=int, choices=[0, 1, 2], default=2,
        help="Increase the verbosity level: 0 silent, [1, 2] verbose.")

    # Create a dict of arguments to pass to the 'main' function
    args = parser.parse_args()
    kwargs = vars(args)
    verbose = kwargs.pop("verbose")
    return kwargs, verbose

"""
Parse the command line.
"""
inputs, verbose = get_cmd_line_args()
tool = "pyconnectome_get_folds_metrics"
timestamp = datetime.now().isoformat()
tool_version = version
params = locals()
runtime = dict([(name, params[name])
               for name in ("tool", "tool_version",
                            "timestamp")])
outputs = None
if verbose > 0:
    pprint("[info] Starting computation of folds metrics...")
    pprint("[info] Runtime:")
    pprint(runtime)
    pprint("[info] Inputs:")
    pprint(inputs)

"""
Start the folds/pits' metrics computation
"""

if inputs["pitsfiles"] is not None:
    # Compute scalar values on pits instead of folds
    # Extract pits coordinates from white/grey matter mesh in physical
    # morphological space and put them in NIFTI voxel space.
    mesh_pits_l, indexes_pits_l = convert_pits(inputs["pitsfiles"][0],
                                               inputs["meshfiles"][0],
                                               inputs["t1"])
    mesh_pits_r, indexes_pits_r = convert_pits(inputs["pitsfiles"][1],
                                               inputs["meshfiles"][1],
                                               inputs["t1"])

    points_l = {}
    for p in range(len(indexes_pits_l)):
        points_l[indexes_pits_l[p]] = np.array([mesh_pits_l[p]])

    points_r = {}
    for p in range(len(indexes_pits_r)):
        points_r[indexes_pits_r[p]] = np.array([mesh_pits_r[p]])

else:
    # Parse the Morphologist graph file to get the fold labels
    labels_l = parse_graph(inputs["graphfile"][0])
    labels_r = parse_graph(inputs["graphfile"][1])

    # Convert the folds in physical morphological space to NIFTI voxel space
    folds_l = convert_folds(inputs["foldsfile"][0], inputs["graphfile"][0],
                            inputs["t1"])
    folds_r = convert_folds(inputs["foldsfile"][1], inputs["graphfile"][1],
                            inputs["t1"])
    points_l = {}
    points_r = {}

    # If no folds were specified, select all folds vertices for the computation
    if inputs["leftfolds"] is None:
        for ind in labels_l.keys():
            points_l[ind] = folds_l[ind].vertices
    # If the user specified folds (-1 == no folds), do the computation on these
    # folds vertices
    elif inputs["leftfolds"][0] != -1:
        for ind in inputs["leftfolds"]:
            points_l[ind] = folds_l[ind].vertices

    if inputs["rightfolds"] is None:
        for ind in labelsR.keys():
            points_r[ind] = folds_r[ind].vertices
    elif inputs["rightfolds"][0] != -1:
        for ind in inputs["rightfolds"]:
            points_r[ind] = folds_r[ind].vertices


# Extract scalar values on folds/pits
measures_l = sphere_integration(inputs["t1"], inputs["scalarfile"], points_l,
                                seg_file=inputs["wgmfile"][0], radius=2)
measures_r = sphere_integration(inputs["t1"], inputs["scalarfile"], points_r,
                                seg_file=inputs["wgmfile"][1], radius=2)

# Write csv and json output
if inputs["pitsfiles"] is not None:
    out_file_l = os.path.join(inputs["outdir"],
                              "Lh_{0}_pits_measure".format(inputs["subject"]))
    out_file_r = os.path.join(inputs["outdir"],
                              "Rh_{0}_pits_measure".format(inputs["subject"]))
else:
    out_file_l = os.path.join(inputs["outdir"],
                              "Lh_{0}_folds_measure".format(inputs["subject"]))
    out_file_r = os.path.join(inputs["outdir"],
                              "Rh_{0}_folds_measure".format(inputs["subject"]))
out_files = {out_file_l: measures_l, out_file_r: measures_r}
for out_file in out_files.keys():
    with open("{0}.json".format(out_file), 'w') as f:
        json.dump(measures_l, f)
    with open("{0}.csv".format(out_file), 'w') as f:
        random_index = out_files[out_file].keys()[0]
        random_point = out_files[out_file][random_index].keys()[0]
        features = []
        if inputs["pitsfiles"] is None:
            header = "Fold_index;PointCoord"
        else:
            header = "Pit_index;PointCoord"
        for feat in out_files[out_file][random_index][random_point].keys():
            features.append(feat)
            vals = out_files[out_file][random_index][random_point][feat].keys()
            for val in vals:
                header = "{0};{1}_{2}".format(header, feat, val)
        f.write(header)
        f.write("\n")

        for index in out_files[out_file].keys():
            for point in out_files[out_file][index].keys():
                line = "{0};{1}".format(index, point)
                for feat in features:
                    vals = out_files[out_file][index][point][feat].keys()
                    for val in vals:
                        line = "{0};{1}".format(line, out_files[out_file]
                                                               [index][point]
                                                               [feat][val])
                f.write(line)
                f.write("\n")

"""
Update the outputs and save them and the inputs in a 'logs' directory.
"""

outputs = []
for ext in ["csv", "json"]:
    outputs.append("{0}.{1}".format(out_file_l, ext))
    outputs.append("{0}.{1}".format(out_file_r, ext))
logdir = os.path.join(inputs["outdir"], "logs")
if not os.path.isdir(logdir):
    os.mkdir(logdir)
params = locals()
for name, final_struct in [("inputs", inputs), ("outputs", outputs),
                           ("runtime", runtime)]:
    log_file = os.path.join(logdir, "{0}.json".format(name))
    with open(log_file, "wt") as open_file:
        json.dump(final_struct, open_file, sort_keys=True, check_circular=True,
                  indent=4)
if verbose > 1:
    print("[final]")
    pprint(outputs)
