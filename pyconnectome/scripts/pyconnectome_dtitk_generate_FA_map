#!/usr/bin/env python
##########################################################################
# NSAp - Copyright (C) CEA, 2018
# Distributed under the terms of the CeCILL-B license, as published by
# the CEA-CNRS-INRIA. Refer to the LICENSE file or to
# http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html
# for details.
##########################################################################

# System import
import os
import argparse
import textwrap
import glob
import re
import json
from datetime import datetime
from argparse import RawTextHelpFormatter
from datetime import datetime
from pprint import pprint

# DTI-TK/TBSS imports
from pyconnectome.tractography.dtitk_tbss import (
    TVMean, generate_FA_map, skeletonize, fslmerge, binarize_4D_FA,
    tbss_4_prestats)

# Pyconnectome imports
from pyconnectome.wrapper import FSLWrapper

# Bredala import
try:
    import bredala
    bredala.USE_PROFILER = False
    bredala.register("pyconnectome.tractography.dtitk_tbss",
                     names=["TVMean", "generate_FA_map", "skeletonize",
                            "fslmerge", "binarize_4D_FA", "tbss_4_prestats"])
except:
    pass

# Script documentation
DOC = """
Generate FA map with DTI-TK/TBSS commands.
------------------------------------------

Steps:
    1) Generate population-specific DTI template with the isotropic 1mm3
    spacing.
    2) Generate the FA map from template.
    3) Generate the white matter skeleton from the FA map.
    4) Generate the subjects concatenated FA maps.
    5) Project all subjects' FA data onto the mean FA skeleton.

Command example on the MAPT data :
python $PROJECT/MAPT/pyconnectome_dtitk_generate_FA_map \
    -t 03990399MRO/dtifit_dtitk_diffeo.nii.gz \
        ...
       /volatile/MAPT_TRACTS/data/M0/03990185BAI/dtifit_dtitk_diffeo.nii.gz \
       /volatile/MAPT_TRACTS/data/M0/03990230CRE/dtifit_dtitk_diffeo.nii.gz \
       /volatile/MAPT_TRACTS/data/M0/03990364BCL/dtifit_dtitk_diffeo.nii.gz \
       /volatile/MAPT_TRACTS/data/M0/02990271GJO/dtifit_dtitk_diffeo.nii.gz \
    -o /volatile/MAPT_TRACTS/data/M0 \
    -V 2
"""


def is_file(filepath):
    """ Check file's existence - argparse 'type' argument.
    """
    if not os.path.isfile(filepath):
        raise argparse.ArgumentError("File does not exist: %s" % filepath)
    return filepath


def is_directory(dirarg):
    """ Type for argparse - checks that directory exists.
    """
    if not os.path.isdir(dirarg):
        raise argparse.ArgumentError(
            "The directory '{0}' does not exist!".format(dirarg))
    return dirarg


# Parse input arguments
def get_cmd_line_args():
    """
    Create a command line argument parser and return a dict mapping
    <argument name> -> <argument value>.
    """
    parser = argparse.ArgumentParser(
        prog="python pyconnectome_preproc_steps",
        description=textwrap.dedent(DOC),
        formatter_class=RawTextHelpFormatter)

    # Required arguments
    required = parser.add_argument_group("required arguments")
    required.add_argument(
        "-t", "--tensor-normalized", type=is_file, required=True, nargs='+',
        help="Paths to the tensors in template space and with 1mm3 isotropic"
             " voxel dimensions.")
    required.add_argument(
        "-o", "--outdir",
        type=is_directory, required=True, metavar="<path>",
        help="Path to the output directory.")

    # Optional argument
    parser.add_argument(
        "-T", "--threshold-fa-skeleton", type=float, default=0.2,
        help="Fa skeleton threshold for tbss_4_prestats.")
    parser.add_argument(
        "-V", "--verbose",
        type=int, choices=[0, 1, 2], default=2,
        help="Increase the verbosity level: 0 silent, [1, 2] verbose.")

    # Create a dict of arguments to pass to the 'main' function
    args = parser.parse_args()
    kwargs = vars(args)
    verbose = kwargs.pop("verbose")
    return kwargs, verbose


"""
Parse the command line.
"""


inputs, verbose = get_cmd_line_args()
tool = "pyconnectome_enigma_tbss"
timestamp = datetime.now().isoformat()
params = locals()
runtime = dict([(name, params[name])
               for name in ("tool", "timestamp")])
outputs = {}
if verbose > 0:
    pprint("[info] Starting tbss with enigma template...")
    pprint("[info] Runtime:")
    pprint(runtime)
    pprint("[info] Inputs:")
    pprint(inputs)


"""
1 - Generate the population-specific DTI template with the isotropic 1mm3
    spacing.
"""


print("Generate the population-specific DTI template with the isotropic"
      " 1mm3 spacing...")

# List normalized dti files
subjects_normalized_file = os.path.join(
    inputs["outdir"], "subjects_normalized.txt")
with open(subjects_normalized_file, 'w') as open_file:
    for t in inputs["tensor_normalized"]:
        open_file.write(t)
        open_file.write("\n")
high_res_template = os.path.join(
    inputs["outdir"], "mean_final_high_res.nii.gz")
TVMean(
    subjects=subjects_normalized_file,
    out_template=high_res_template,
    typep="ORIGINAL",
    interp="LEI")
outputs["mean_high_resolution_template"] = high_res_template


"""
2 - Generate the FA map of the high-resolution population-specific DTI
    template.
"""


print("Generate template FA map...")
high_res_template = os.path.join(
    inputs["outdir"], "mean_final_high_res.nii.gz")
mean_fa_map = os.path.join(inputs["outdir"], "mean_FA.nii.gz")
fa_map = generate_FA_map(
    dti_file=high_res_template,
    output_fa=mean_fa_map)
outputs["mean_FA_map"] = mean_fa_map

"""
3 - Generate the white matter skeleton from the high-resolution FA map of
    the DTI template.
"""
print("Generate skeleton from template FA map...")
fa_skeleton = os.path.join(inputs["outdir"], "mean_FA_skeleton.nii.gz")
skeletonize(
    input_file=fa_map,
    output_file=fa_skeleton)
outputs["mean_FA_skeleton"] = fa_skeleton


"""
4 - Generate the FA map of the spatially normalized high-resolution DTI
    data.
"""


print("Generate FA maps of DTI data...")
subjects_fa_map = []
for sub in inputs["tensor_normalized"]:
    sub_fa_map = generate_FA_map(
        dti_file=sub,
        output_fa=sub.replace(".nii.gz", "_FA.nii.gz"))
    subjects_fa_map.append(sub_fa_map)
allfa = os.path.join(inputs["outdir"], "all_FA.nii.gz")
allfa = fslmerge(
    images=subjects_fa_map,
    concatenated_output=allfa,
    time=True)
outputs["all_FA"] = allfa

mean_fa_mask = os.path.join(inputs["outdir"], "mean_FA_mask.nii.gz")
binarize_4D_FA(
    fa_4D=allfa,
    output=mean_fa_mask)
outputs["mean_FA_mask"] = mean_fa_mask


"""
5 - Process to tbss procedure.
"""


# Place the TBSS relevant files into a folder that TBSS expects
# Create a directory called tbss with a subdirectory called stats.
# Copy mean_FA_skeleton, all_FA, and mean_FA_mask to the stats
# subdirectory.
tbss_dir = os.path.join(inputs["outdir"], "tbss")
if not os.path.isdir(tbss_dir):
    os.mkdir(tbss_dir)
tbss_stat_dir = os.path.join(tbss_dir, "stats")
if not os.path.isdir(tbss_stat_dir):
    os.mkdir(tbss_stat_dir)
tbss_stat_files = [mean_fa_map, fa_skeleton, allfa, mean_fa_mask]
for f in tbss_stat_files:
    cmd = ["cp", f, tbss_stat_dir]
    cmd = " ".join(cmd)
    os.system(cmd)
outputs["tbss_dir"] = tbss_dir
outputs["tbss_stats_dir"] = tbss_stat_dir

# Thresholds the mean FA skeleton image at the chosen threshold with
# tbss_4_prestats
tbss_4_prestats(
    output_dir=tbss_dir,
    threshold=inputs["threshold_fa_skeleton"])


"""
Update the outputs and save them and the inputs in a 'logs' directory.
"""

logdir = os.path.join(inputs["outdir"], "logs")
if not os.path.isdir(logdir):
    os.mkdir(logdir)
for name, final_struct in [("inputs", inputs), ("outputs", outputs),
                           ("runtime", runtime)]:
    log_file = os.path.join(
        logdir, "pyconnectome_dtitk_create_templates_{0}.json".format(name))
    with open(log_file, "wt") as open_file:
        json.dump(final_struct, open_file, sort_keys=True, check_circular=True,
                  indent=4)

# Print outputs
if verbose > 0:
    pprint("[Info] Outputs:")
    pprint(outputs)
