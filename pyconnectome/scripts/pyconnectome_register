#! /usr/bin/env python
##########################################################################
# NSAp - Copyright (C) CEA, 2013 - 2017
# Distributed under the terms of the CeCILL-B license, as published by
# the CEA-CNRS-INRIA. Refer to the LICENSE file or to
# http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html
# for details.
##########################################################################

# System import
from __future__ import print_function
import argparse
import os
import shutil
from datetime import datetime
import json
from pprint import pprint
import textwrap
from argparse import RawTextHelpFormatter

# Bredala import
try:
    import bredala
    bredala.USE_PROFILER = False
    bredala.register("pyconnectome.utils.segtools",
                     names=["bet2", "fast"])
    bredala.register("pyconnectome.utils.regtools",
                     names=["flirt", "fnirt"])
except:
    pass

# Package import
from pyconnectome import __version__ as version
from pyconnectome import DEFAULT_FSL_PATH
from pyconnectome.wrapper import FSLWrapper
from pyconnectome.utils.segtools import bet2
from pyconnectome.utils.segtools import fast
from pyconnectome.utils.regtools import flirt
from pyconnectome.utils.regtools import fnirt


# Parameters to keep trace
__hopla__ = ["runtime", "inputs", "outputs"]


# Script documentation
doc = """
FSL registration
~~~~~~~~~~~~~~~~

Rigid/affine or non linear registration with FSL using flirt and fnirt.

Command:

python $HOME/git/pyfsl/pyconnectome/scripts/pyconnectome_register \
    -v 2 \
    -s test_fsl \
    -o /volatile/nsap/recalage_cathy/results \
    -i /volatile/nsap/recalage_cathy/T1W_gado.nii.gz \
    -r /usr/share/fsl/data/standard/MNI152_T1_1mm.nii.gz \
    -j /usr/share/fsl/data/standard/MNI152_T1_1mm_brain.nii.gz \
    -x /volatile/nsap/recalage_cathy/mask_lesion.nii.gz /volatile/nsap/recalage_cathy/mask_necrosis.nii.gz \
    -c /etc/fsl/5.0/fsl.sh \
    -k 3 \
    -t 1 \
    -f 0.45 \
    -b \
    -a normmi \
    -n \
    -d
"""


def is_file(filearg):
    """ Type for argparse - checks that file exists but does not open.
    """
    if not os.path.isfile(filearg):
        raise argparse.ArgumentError(
            "The file '{0}' does not exist!".format(filearg))
    return filearg


def is_directory(dirarg):
    """ Type for argparse - checks that directory exists.
    """
    if not os.path.isdir(dirarg):
        raise argparse.ArgumentError(
            "The directory '{0}' does not exist!".format(dirarg))
    return dirarg


parser = argparse.ArgumentParser(
    prog="pyconnectome_register",
    description=textwrap.dedent(DOC),
    formatter_class=RawTextHelpFormatter))
parser.add_argument(
    "-v", "--verbose", dest="verbose", type=int, choices=[0, 1, 2], default=0,
    help="increase the verbosity level: 0 silent, [1, 2] verbose.")
parser.add_argument(
    "-e", "--erase", dest="erase", action="store_true",
    help="if activated, clean the result folder if already created.")
parser.add_argument(
    "-o", "--outdir", dest="outdir", metavar="PATH", type=is_directory,
    help="the analysis output directory.")
parser.add_argument(
    "-s", "--sid", dest="sid", required=True,
    help="the subject identifier.")
parser.add_argument(
    "-i", "--inputfile", dest="inputfile", type=is_file,
    required=True, help="the input MRI volume.")
parser.add_argument(
    "-r", "--referencefile", dest="referencefile", type=is_file,
    required=True, help="the template file used as the reference volume.")
parser.add_argument(
    "-j", "--referencebrainfile", dest="referencebrainfile", type=is_file,
    required=True, help="the template brain file used as the reference volume.")
parser.add_argument(
    "-x", "--extrafiles", dest="extrafiles", type=is_file, nargs="*",
    help="list of files to apply transform to.")
parser.add_argument(
    "-c", "--fslconfig", dest="fslconfig", type=is_file,
    help="path to the FSL configuration file.")
parser.add_argument(
    "-d", "--dotissues", dest="dotissues", action="store_true",
    help="if activated, segment the scan tissues with FAST and apply spatial "
         "intensity variations correction.")
parser.add_argument(
    "-t", "--intype", dest="intype", default=1, type=int, choices=range(1, 4),
    help="type of the input image 1=T1, 2=T2, 3=PD")
parser.add_argument(
    "-k", "--nbklass", dest="nbklass", default=3, type=int,
    help="the number of class in the FAST modelization.")
parser.add_argument(
    "-b", "--dobrain", dest="dobrain", action="store_true",
    help="if set, use the BET2 routine to segment the subject brain.")
parser.add_argument(
    "-f", "--brainthr", dest="brainthr", type=float, default=0.5,
    help="the BET2 fractional intensity threshold (0->1).")
parser.add_argument(
    "-a", "--cost", dest="cost", default="normmi",
    choices=("mutualinfo", "corratio", "normcorr", "normmi", "leastsq",
             "labeldiff", "bbr"),
    help="the affine cost function type.")
parser.add_argument(
    "-n", "--dononlinear", dest="dononlinear", action="store_true",
    help="if set, use the FNIRT routine to align the subject brain to the "
         "template with a non linear transformation.")
args = parser.parse_args()
inputs = vars(args)
verbose = inputs.pop("verbose")


"""
First construct the subject working directory and check its existance on
the file system.
"""
tool = "pyconnectome_register"
timestamp = datetime.now().isoformat()
tool_version = version
fsl_config = args.fslconfig or DEFAULT_FSL_PATH
fsl_version = FSLWrapper([], shfile=fsl_config).version
params = locals()
runtime = dict([(name, params[name])
               for name in ("fsl_config", "tool", "tool_version",
                            "fsl_version", "timestamp")])
outputs = None
subjdir = os.path.join(inputs["outdir"], inputs["sid"])
if inputs["erase"] and os.path.isdir(subjdir):
    shutil.rmtree(subjdir)
if not os.path.isdir(subjdir):
    os.mkdir(subjdir)


"""
Step 1: Brain extraction
"""
if inputs["dobrain"]:
    bet_dir = os.path.join(subjdir, "bet")
    if not os.path.isdir(bet_dir):
        os.mkdir(bet_dir)
    (brain_file, mask_file, mesh_file, outline_file, inskull_mask_file,
     inskull_mesh_file, outskull_mask_file, outskull_mesh_file,
     outskin_mask_file, outskin_mesh_file, skull_mask_file) = bet2(
        input_file=inputs["inputfile"],
        output_fileroot=bet_dir,
        outline=False,
        mask=True,
        skull=False,
        nooutput=False,
        f=inputs["brainthr"],
        g=0,
        radius=None,
        smooth=None,
        c=None,
        threshold=False,
        mesh=False,
        shfile=fsl_config)
else:
    mask_file, mesh_file, outline_file, inskull_mask_file = (None, ) * 4
    nskull_mesh_file, outskull_mesh_file, outskin_mask_file = (None, ) * 3
    skull_mask_file, outskin_mesh_file, outskull_mask_file = (None, ) * 3
    brain_file =  biascorrected_anatfile
if verbose > 0:
    print("[result] Brain image: {0}.".format(brain_file))
    print("[result] Brain mask image: {0}.".format(mask_file))


"""
Step 2: Tissue segmentation and spatial intensity variations correction.
"""
if inputs["dotissues"]:
    fast_dir = os.path.join(subjdir, "fast")
    if not os.path.isdir(fast_dir):
        os.mkdir(fast_dir)
    fast_fileroot = os.path.join(
        fast_dir, os.path.basename(inputs["inputfile"]).split(".")[0])
    tpm, tsm, segmentation_anatfile, bias_anatfile, biascorrected_anatfile = fast(
        input_file=brain_file,
        out_fileroot=fast_fileroot,
        klass=inputs["nbklass"],
        im_type=inputs["intype"],
        segments=True,
        bias_field=True,
        bias_corrected_im=True,
        probabilities=True,
        shfile=fsl_config)
else:
    tpm, tsm, segmentation_anatfile, bias_anatfile = (None, None, None, None)
    biascorrected_anatfile = brain_file
if verbose > 0:
    print("[result] Antomical tissues: {0}.".format(segmentation_anatfile))
    print("[result] Antomical bias field: {0}.".format(bias_anatfile))
    print("[result] Antomical bias corrected: {0}.".format(
        biascorrected_anatfile))


"""
Step 3: Affine registration
"""
flirt_dir = os.path.join(subjdir, "flirt")
if not os.path.isdir(flirt_dir):
    os.mkdir(flirt_dir)
basename = os.path.basename(biascorrected_anatfile).split(".")[0]
affine_file, affine_omat = flirt(
    in_file=inputs["inputfile"],
    ref_file=inputs["referencefile"],
    omat=os.path.join(flirt_dir, "flirt_omat_{0}.txt".format(basename)),
    out=os.path.join(flirt_dir, "flirt_{0}.nii.gz".format(basename)),
    init=None,
    cost=inputs["cost"],
    usesqform=False,
    displayinit=False,
    anglerep="euler",
    bins=256,
    interp="trilinear",
    dof=12,
    applyxfm=False,
    applyisoxfm=None,
    verbose=verbose,
    shfile=fsl_config)
if verbose > 0:
    print("[result] Affine: {0}.".format(affine_file))
    print("[result] Affine transformation: {0}.".format(affine_omat))


"""
Step 4: Non linear registration
"""
if inputs["dononlinear"]:
    fnirt_dir = os.path.join(subjdir, "fnirt")
    if not os.path.isdir(fnirt_dir):
        os.mkdir(fnirt_dir)
    cout, iout, fout, jout, refout, intout, logout = fnirt(
        in_file=brain_file,
        ref_file=inputs["referencebrainfile"],
        affine_file=affine_omat,
        outdir=fnirt_dir,
        inmask_file=None,
        verbose=verbose,
        shfile=fsl_config)
else:
    cout, iout, fout, jout, refout, intout, logout = (None, ) * 7


"""
Update the outputs and save them and the inputs in a 'logs' directory.
"""
logdir = os.path.join(subjdir, "logs")
if not os.path.isdir(logdir):
    os.mkdir(logdir)
params = locals()
outputs = dict([(name, params[name])
               for name in ("tpm", "tsm", "segmentation_anatfile",
                            "bias_anatfile", "biascorrected_anatfile",
                            "brain_file", "mask_file",
                            "affine_file", "affine_omat", "cout", "iout",
                            "fout", "jout", "refout", "intout", "logout")])
for name, final_struct in [("inputs", inputs), ("outputs", outputs),
                           ("runtime", runtime)]:
    log_file = os.path.join(logdir, "{0}.json".format(name))
    with open(log_file, "wt") as open_file:
        json.dump(final_struct, open_file, sort_keys=True, check_circular=True,
                  indent=4)
if verbose > 1:
    print("[info] Outputs:")
    pprint(outputs)
