#! /usr/bin/env python
# -*- coding: utf-8 -*
##########################################################################
# NSAp - Copyright (C) CEA, 2018
# Distributed under the terms of the CeCILL-B license, as published by
# the CEA-CNRS-INRIA. Refer to the LICENSE file or to
# http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html for details.
##########################################################################

# System import
import os
import argparse
import textwrap
from argparse import RawTextHelpFormatter
from datetime import datetime
from pprint import pprint

# Bredala module
try:
    import bredala
    bredala.USE_PROFILER = False
    bredala.register("pyconnectome.utils.filetools",
                     names=["parse_graph"])
    bredala.register("pyconnectome.metrics.dfold",
                     names=["convert_fold", "sphere_integration"])
except:
    pass

# Package import
from pyconnectome import __version__ as version
from pyconnectome.utils.filetools import parse_graph
from pyconnectome.metrics.dfold import convert_folds
from pyconnectome.metrics.dfold import sphere_integration

# Third party import
import json

# Parameters to keep trace
__hopla__ = ["runtime", "inputs", "outputs"]


# Script documentation
DOC = """


Command example on the HCP data :

python pyconnectome_get_folds_metrics \
    -o $PROJECT/HCP_FOLDS/TEST_OUTPUT \
    -ff /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/L101006_default_session_auto.data/aims_Tmtktri.gii \
    -t /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/101006.nii.gz \
    -s $PROJECT/HCP_FOLDS/TEST_OUTPUT/dtifit_FA.nii.gz \
    -sb 101006 \
    -g /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/L101006_default_session_auto.arg \
    -f 94 86 \
    -wm /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/mesh/101006_Lwhite.gii


Bonus :
# Create scalar file with wrapped command dtifit if needed
if 0:
    dwi_file="/neurospin/hcp/ANALYSIS/3T_connectomist/101006/preproc/3000/dwi.nii.gz"
    bvecs="/neurospin/hcp/ANALYSIS/3T_connectomist/101006/preproc/3000/bvecs"
    bvals="/neurospin/hcp/ANALYSIS/3T_connectomist/101006/preproc/3000/bvals"
    mask="/neurospin/hcp/PROCESSED/3T_diffusion_preproc/101006/T1w/Diffusion/nodif_brain_mask.nii.gz"
    output_dir="$PROJECT/HCP_FOLDS/TEST_OUTPUT"
    dtifit(dwi_file,bvecs,bvals,mask,output_dir,wls=True,save_tensor=True)

"""


def is_file(filepath):
    """ Check file's existence - argparse 'type' argument.
    """
    if not os.path.isfile(filepath):
        raise argparse.ArgumentError("File does not exist: %s" % filepath)
    return filepath


def is_directory(dirarg):
    """ Type for argparse - checks that directory exists.
    """
    if not os.path.isdir(dirarg):
        raise argparse.ArgumentError(
            "The directory '{0}' does not exist!".format(dirarg))
    return dirarg


# Parse input arguments
def get_cmd_line_args():
    """
    Create a command line argument parser and return a dict mapping
    <argument name> -> <argument value>.
    """
    parser = argparse.ArgumentParser(
        prog="python pyconnectome_get_folds_metrics",
        description=textwrap.dedent(DOC),
        formatter_class=RawTextHelpFormatter)

    # Required arguments
    required = parser.add_argument_group("required arguments")
    required.add_argument(
        "-o", "--outdir",
        type=is_directory, required=True, metavar="<path>",
        help="Directory where to output.")
    required.add_argument(        
        "-sb", "--subject",
        type=str, required=True, help="Subject ID.")
    required.add_argument(
        "-ff", "--foldsfile",
        type=is_file, required=True, metavar="<path>",
        help="Path to the folds .gii file.")
    required.add_argument(
        "-t", "--t1",
        type=is_file, required=True, metavar="<path>",
        help="Path to the T1 image file.")
    required.add_argument(
        "-s", "--scalarfile",
        type=is_file, required=True, metavar="<path>",
        help="Path to the scalar image file.")
    required.add_argument(
        "-g", "--graphfile",
        type=is_file, required=True, metavar="<path>",
        help="Path to the morphologist graph file.")

    # Optional argument
    parser.add_argument(
        "-f", "--folds",
        type=int, nargs='+',
        help="Selection of folds indexes on which to compute value \
             (e.g : 94).")
    parser.add_argument(
        "-wm", "--whitefile",
        type=is_file, metavar="<path>",
        help="Path to the white matter surface file.")
    parser.add_argument(
        "-gm", "--greyfile",
        type=is_file, metavar="<path>",
        help="Path to the grey matter surface file.")
    parser.add_argument(
        "-v", "--verbose",
        type=int, choices=[0, 1, 2], default=2,
        help="Increase the verbosity level: 0 silent, [1, 2] verbose.")

    # Create a dict of arguments to pass to the 'main' function
    args = parser.parse_args()
    kwargs = vars(args)
    verbose = kwargs.pop("verbose")
    return kwargs, verbose

"""
Parse the command line.
"""
inputs, verbose = get_cmd_line_args()
tool = "pyconnectome_get_folds_metrics"
timestamp = datetime.now().isoformat()
date = datetime.now().date()
date = "{0}_{1}_{2}".format(date.year, date.month, date.day)
tool_version = version
params = locals()
runtime = dict([(name, params[name])
               for name in ("tool", "tool_version",
                            "timestamp")])
outputs = None
if verbose > 0:
    pprint("[info] Starting computation of folds metrics...")
    pprint("[info] Runtime:")
    pprint(runtime)
    pprint("[info] Inputs:")
    pprint(inputs)


graph_file = inputs["graphfile"]
folds_file = inputs["foldsfile"]
t1file = inputs["t1"]
scalarfile = inputs["scalarfile"]
outdir = inputs["outdir"]
folds_indexes = inputs["folds"]
white_file = inputs["whitefile"]
grey_file = inputs["greyfile"]
subject = inputs["subject"]

"""
Start the folds' metrics computation
"""

labels = parse_graph(graph_file)
folds = convert_folds(folds_file, graph_file, t1file)

folds_ = {}
if folds_indexes is None:
    for ind in labels.keys():
        folds_[ind] = folds[ind]
else:
    for ind in folds_indexes:
        folds_[ind] = folds[ind]

measures = sphere_integration(t1file, folds_, [scalarfile], wm_file=white_file,
                              gm_file=grey_file, radius=2)

"""
Save output in json and csv files
"""

# JSON
out_file = os.path.join(outdir, "{0}_folds_measure_{0}.json"
                        .format(subject, date))
with open(out_file, 'w') as outfile:
    json.dump(measures, outfile)

# CSV
out_file = os.path.join(outdir, "{0}_folds_measure_{1}.csv"
                        .format(subject,date))
with open(out_file, 'w') as f:
    f.write("Fold;PointCoord;FA_mean_all;FA_mean_wm;FA_mean_gm;FA_median_all; \
            FA_median_wm;FA_median_gm\n")
    for fold in measures.keys():
        for point in measures[fold].keys():
            line = "{0};{1}".format(labels[fold], point)
            FA = measures[fold][point]["dtifit_FA"]
            line_measures = "{0};{1};{2};{3};{4};{5}".format(
                             FA["global_mean"], FA["wm_mean"], FA["gm_mean"],
                             FA["global_median"], FA["wm_median"],
                             FA["gm_median"])
            line = "{0};{1}".format(line, line_measures)
            f.write(line)
            f.write("\n")
