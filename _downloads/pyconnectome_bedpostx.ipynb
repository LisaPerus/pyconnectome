{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nPyconnectome Bedpostx\n=====================\n\nExample automatically generated from package script.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# System modules\nfrom __future__ import print_function\nimport os\nimport glob\nimport numpy\nimport shutil\nimport argparse\nimport textwrap\nfrom datetime import datetime\n\n\n# Bredala module\ntry:\n    import bredala\n    bredala.USE_PROFILER = False\n    bredala.register(\"pyconnectome.utils.segtools\",\n                     names=[\"bet2\"])\n    bredala.register(\"pyconnectome.models.deconvolution\",\n                     names=[\"bedpostx\", \"bedpostx_datacheck\"])\n    bredala.register(\"pyconnectome.utils.filetools\",\n                     names=[\"extract_image\"])\n    bredala.register(\"clindmri.plot.slicer\",\n                     names=[\"plot_image\"])\nexcept:\n    pass\n\n# Package import\nfrom pyconnectome import __version__ as version\nfrom pyconnectome import DEFAULT_FSL_PATH\nfrom pyconnectome.wrapper import FSLWrapper\nfrom pyconnectome.utils.segtools import bet2\nfrom pyconnectome.utils.filetools import extract_image\nfrom pyconnectome.models.deconvolution import bedpostx\nfrom pyconnectome.models.deconvolution import bedpostx_datacheck\n\n\n# Parameters to keep trace\n__hopla__ = [\"runtime\", \"inputs\", \"outputs\"]\n\n\n# Script documentation\ndoc = \"\"\"\nFSL Bedpostx\n~~~~~~~~~~~~\n\nPerforms a parametric deconvolution of the diffusion signal to fiber\norientations using a stick and ball model.\n\n**Steps**\n\n1 - Extract the brain using BET on the non weighted image.\n2 - Estimate fiber orientations using FSL Bedpostx.\n\n**Input files**\n\n- The *.bval files contain a scalar value for each applied gradient,\n  corresponding to the respective b-value.\n- The *.bvec files contain a 3x1 vector for each gradient, indicating the\n  gradient direction.\n- The diffuson data: the ith volume in the data corresponds to a measurement\n  obtained after applying a diffusion-sensitising gradient with a b-value given\n  by the ith entry in *.bval and a gradient direction given by the ith vector\n  in *.bvec.\n\n**Output files**\n\nFor every model parameter a distribution of values is estimated.\n- mean_*samples.nii.gz files: the mean of this distribution is saved for the\n  angular parameters (theta and phi) and the f anisotropy (3D volume).\n- merged_*samples.nii.gz files: contain the parameters used in the tractography\n  algorithm (e.g. orientations), samples from the theta, phi and f (4D image)\n  are saved.\nFor each fiber compartment an orientation and a volume fraction is estimated.\nThe orientation is described in spherical coordinates by two angles, theta and\nphi.\n\nFor example the files:\n- (mean_f2samples.nii.gz, mean_th2samples.nii.gz, mean_ph2samples.nii.gz)\n  describe the means values of the distributions estimated for the volume\n  fraction and orientation of fiber 2.\n- (merged_f2samples.nii.gz, merged_ph2samples.nii.gz,merged_th2samples.nii.gz)\n  describe samples from these distributions.\n\n**Command**\n\npython $HOME/git/pyconnectome/pyconnectome/scripts/pyconnectome_bedpostx \\\n    -c /etc/fsl/5.0/fsl.sh \\\n    -s 000043561374 \\\n    -f /volatile/imagen/dmritest/001/raw/hardi-b1500-1-001.nii.gz \\\n    -g /volatile/imagen/dmritest/001/raw/hardi-b1500-1-001.bvec \\\n    -b /volatile/imagen/dmritest/001/raw/hardi-b1500-1-001.bval \\\n    -d /volatile/imagen/dmritest/fsl \\\n    -t 0.25 \\\n     --burn 10 \\\n    -e \\\n    -v 2\n\"\"\"\n\n\ndef is_file(filearg):\n    \"\"\" Type for argparse - checks that file exists but does not open.\n    \"\"\"\n    if not os.path.isfile(filearg):\n        raise argparse.ArgumentError(\n            \"The file '{0}' does not exist!\".format(filearg))\n    return filearg\n\n\ndef is_directory(dirarg):\n    \"\"\" Type for argparse - checks that directory exists.\n    \"\"\"\n    if not os.path.isdir(dirarg):\n        raise argparse.ArgumentError(\n            \"The directory '{0}' does not exist!\".format(dirarg))\n    return dirarg\n\n\nparser = argparse.ArgumentParser(\n    formatter_class=argparse.RawDescriptionHelpFormatter,\n    description=textwrap.dedent(doc))\nrequired = parser.add_argument_group(\"required arguments\")\n\nrequired.add_argument(\n    \"-c\", \"--config\", dest=\"fslconfig\", metavar=\"FILE\",\n    help=\"the FSL configuration file.\", type=is_file)\nrequired.add_argument(\n    \"-s\", \"--subjectid\", dest=\"subjectid\", required=True,\n    help=\"the subject identifier.\")\nrequired.add_argument(\n    \"-f\", \"--diffusionfile\", dest=\"diffusion_file\", metavar=\"FILE\",\n    required=True,\n    help=\"the diffusion data after correction for distorsions.\", type=is_file)\nrequired.add_argument(\n    \"-g\", \"--bvecsfile\", dest=\"bvecs_file\", metavar=\"FILE\", required=True,\n    help=\"the *.bvec files contain a 3x1 vector for each gradient, \"\n         \"indicating the gradient direction.\", type=is_file)\nrequired.add_argument(\n    \"-b\", \"--bvalsfile\", dest=\"bvals_file\", metavar=\"FILE\", required=True,\n    help=\"the *.bval files contain a scalar value for each applied gradient, \"\n         \"corresponding to the respective b-value.\", type=is_file)\nrequired.add_argument(\n    \"-d\", \"--fsldir\", dest=\"fsldir\", required=True, metavar=\"PATH\",\n    help=\"the FSL processing home directory.\", type=is_directory)\n\nparser.add_argument(\n    \"-t\", \"--thres\", dest=\"thres\", default=0.5, type=float,\n    help=\"fractional intensity threshold (0->1), smaller values give larger\"\n    \" brain outline estimates.\")\nparser.add_argument(\n    \"-n\", \"--nfiber\", dest=\"nfiber\", default=3,\n    help=\"number of fibers per voxel, integer >= 1.\", type=int)\nparser.add_argument(\n    \"-m\", \"--model\", dest=\"model\", choices=[1, 2, 3],\n    default=2,\n    help=\"deconvolution model. \"\n         \"1: single-shell, with sticks, \"\n         \"2: multi-shell, with sticks with a range of diffusivities, \"\n         \"3: multi-shell, with zeppelins.\", type=int)\nparser.add_argument(\n    \"--rician\", dest=\"rician\", action=\"store_true\",\n    help=\"a Rician noise modeling to replace the default Gaussian noise\"\n         \" assumption.\")\nparser.add_argument(\n    \"--burn\", dest=\"burnin\", default=1000, type=int,\n    help=\"burnin period: number of iterations before starting the sampling.\")\nparser.add_argument(\n    \"--graph\", dest=\"graphics\", action=\"store_true\",\n    help=\"if activated compute quality controls on the BedPostx outputs.\")\nparser.add_argument(\n    \"-e\", \"--erase\", dest=\"erase\", action=\"store_true\",\n    help=\"if activated, clean the subject folder.\")\nparser.add_argument(\n    \"-v\", \"--verbose\", dest=\"verbose\", type=int, choices=[0, 1, 2], default=0,\n    help=\"increase the verbosity level: 0 silent, [1, 2] verbose.\")\nparser.add_argument(\n    \"--parallel\", dest=\"parallel\", action=\"store_true\",\n    help=\"If set use Condor to parallelize FSL on your local workstation.\")\n\n# parsing arguments\nargs = parser.parse_args()\n\n\n# Import graphics modules if necessary\nif args.graphics:\n    from clindmri.plot.slicer import plot_image"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "First check if the subject FSL directory exists on the file system, and\nclean it if requested.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "tool = \"pyconnectome_bedpostx\"\ntimestamp = datetime.now().isoformat()\ntool_version = version\nfsl_config = args.fslconfig or DEFAULT_FSL_PATH\nfsl_version = FSLWrapper([], shfile=fsl_config).version\nparams = locals()\nruntime = dict([(name, params[name])\n               for name in (\"fsl_config\", \"tool\", \"tool_version\",\n                            \"fsl_version\", \"timestamp\")])\nif args.verbose > 0:\n    print(\"[info] Starting FSL bedpostx ...\")\n    print(\"[info] Directory: {0}.\".format(args.fsldir))\n    print(\"[info] Subject: {0}.\".format(args.subjectid))\n    print(\"[info] Diffusion data: {0}.\".format(args.diffusion_file))\n    print(\"[info] Diffusion bvals: {0}.\".format(args.bvals_file))\n    print(\"[info] Diffusion bvecs: {0}.\".format(args.bvecs_file))\n    print(\"[info] FSL version: {0}.\".format(fsl_version))\nsubjdir = os.path.join(args.fsldir, args.subjectid)\nsubject = args.subjectid\ndiffusion_file = args.diffusion_file\nbvals_file = args.bvals_file\nbvecs_file = args.bvecs_file\nthres = args.thres\nnfiber = args.nfiber\nmodel = args.model\nrician = args.rician\nburnin = args.burnin\nparallel = args.parallel\nparams = locals()\ninputs = dict([(name, params[name])\n               for name in (\"subjdir\", \"subject\", \"diffusion_file\",\n                            \"bvecs_file\", \"bvals_file\", \"nfiber\", \"thres\",\n                            \"model\", \"rician\", \"burnin\", \"parallel\")])\noutputs = None\nif args.erase and os.path.isdir(subjdir):\n    shutil.rmtree(subjdir)\nif not os.path.isdir(subjdir):\n    os.mkdir(subjdir)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Diffusion Processing\n~~~~~~~~~~~~~~~~~~~~\n\nAt this point we have a motion- & artifact-corrected image, and the corrected\ngradient table.\n\nFrom this diffusion dataset, we want to compute a mask of the\nnon-diffusion-weighted image.\n\nNon-diffusion-weighted mask\n---------------------------\n\nWe need to generate a mask on which the model is estimated. We first select the\nfirst non-diffusion weighted volume of the diffusion sequence and then use\n'bet2' on this image with a fractional intensity threshold of 0.25\n(that can be customized but is generally a robust threshold to remove\nunwanted tissue from a non-diffusion weighted image) and the 'm' option that\ncreates a binary 'nodif_brain_mask' image.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Get the b0 file\nbvals = numpy.loadtxt(args.bvals_file).tolist()\nb0_index = bvals.index(0)\nb0_file = os.path.join(subjdir, \"nodif.nii.gz\")\nif not os.path.isfile(b0_file):\n    extract_image(\n        args.diffusion_file,\n        index=b0_index,\n        out_file=b0_file)\n\n# Create a pdf snap of the b0 image\nif args.graphics:\n    qcdir = os.path.join(subjdir, \"qc\")\n    if not os.path.isdir(qcdir):\n        os.mkdir(qcdir)\n    snap_file = os.path.join(qcdir, \"nodif.pdf\")\n    plot_image(b0_file, snap_file=snap_file, name=\"nodif\")\n\n# Generate a brain mask on the corrected b0 data\nb0_brain_file = os.path.join(subjdir, \"nodif_brain\")\nbet_files = glob.glob(b0_brain_file + \"*\")\nif len(bet_files) == 0:\n    (output, mask_file, mesh_file, outline_file,\n     inskull_mask_file, inskull_mesh_file,\n     outskull_mask_file, outskull_mesh_file, outskin_mask_file,\n     outskin_mesh_file, skull_mask_file) = bet2(\n        b0_file,\n        b0_brain_file,\n        mask=True,\n        f=thres,\n        shfile=fsl_config)\nelse:\n    mask_file = sorted(bet_files)[0]\n    if not os.path.isfile(mask_file):\n        raise ValueError(\"FileDoesNotExist: '{0}'.\".format(mask_file))\n\n# Create a pdf snap of the brain mask\nif args.graphics:\n    snap_file = os.path.join(qcdir, \"bet.pdf\")\n    plot_image(b0_file, contour_file=mask_file, snap_file=snap_file,\n               name=\"bet\")"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Generating PDFs\n---------------\n\nWe use 'bedpostx' to generate PDFs of the diffusion direction. 'bedpostx' takes\nabout 5 hours of compute time. This routine need specific files that are\nchecked with the 'bedpostx_datacheck' command.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Copy all necessary files in the same repertory for the bedpostx execution\nbedpostx_indir = os.path.join(subjdir, \"diffusion\")\nbedpostx_outdir = os.path.join(subjdir, \"diffusion.bedpostX\")\nif not os.path.isdir(bedpostx_indir):\n    os.mkdir(bedpostx_indir)\nif not os.path.isdir(bedpostx_outdir) or len(os.listdir(bedpostx_outdir)) == 0:\n\n\n    # Create/check bedpostx input directory\n    shutil.copy2(mask_file, bedpostx_indir)\n    data_ext = \".\" + \".\".join(diffusion_file.split(\".\")[1:])\n    shutil.copy2(diffusion_file,\n                 os.path.join(bedpostx_indir, \"data\" + data_ext))\n    shutil.copy2(bvecs_file, os.path.join(bedpostx_indir, \"bvecs\"))\n    shutil.copy2(bvals_file, os.path.join(bedpostx_indir, \"bvals\"))\n    if not bedpostx_datacheck(bedpostx_indir, fslconfig=fsl_config):\n        raise ValueError(\"'{0}' does not contain the data expected by \"\n                         \"'bedpostx'.\".format(bedpostx_indir))\n\n    # Execute bedpostx\n    (bedpostx_outdir, merged_th, merged_ph, merged_f, mean_th, mean_ph, mean_f,\n     mean_d, mean_S0, dyads) = bedpostx(\n        bedpostx_indir,\n        n=nfiber,\n        model=model,\n        rician=rician,\n        b=burnin,\n        fslconfig=fsl_config,\n        fsl_parallel=parallel)\nmerged_files = glob.glob(os.path.join(bedpostx_outdir, \"merged*\"))\nif len(merged_files) == 0:\n    raise ValueError(\"FilesDoNotExist: in '{0}'.\".format(bedpostx_outdir))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Update the outputs and save them and the inputs in a 'logs' directory.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "logdir = os.path.join(subjdir, \"logs\")\nif not os.path.isdir(logdir):\n    os.mkdir(logdir)\nparams = locals()\noutputs = dict([(name, params[name])\n                for name in (\"b0_file\", \"b0_brain_file\", \"mask_file\",\n                             \"merged_files\", \"bedpostx_outdir\")])\nfor name, final_struct in [(\"inputs\", inputs), (\"outputs\", outputs),\n                           (\"runtime\", runtime)]:\n    log_file = os.path.join(logdir, \"{0}.json\".format(name))\n    with open(log_file, \"wt\") as open_file:\n        json.dump(final_struct, open_file, sort_keys=True, check_circular=True,\n                  indent=4)\nif args.verbose > 1:\n    print(\"[final]\")\n    pprint(outputs)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}