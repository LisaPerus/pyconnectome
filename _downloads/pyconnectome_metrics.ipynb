{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nPyconnectome Metrics\n====================\n\nExample automatically generated from package script.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# System modules\nfrom __future__ import print_function\nimport os\nimport shutil\nimport json\nimport argparse\nfrom datetime import datetime\nfrom pprint import pprint\nimport numpy\nimport networkx\nimport bct\nimport csv\nimport copy\nimport textwrap\nfrom argparse import RawTextHelpFormatter\n\n# Bredala module\ntry:\n    import bredala\n    bredala.USE_PROFILER = False\n    bredala.register(\"pyconnectome.metrics.schcc\",\n                     names=[\"basic_network_analysis\",\n                            \"advanced_network_analysis\", \"create_graph\"])\n    bredala.register(\"pyconnectome.plotting.network\",\n                     names=[\"get_surface_parcellation_centroids\",\n                            \"plot_network\", \"dict2list\"])\nexcept:\n    pass\n\n# Package import\nfrom pyconnectome import __version__ as version\nfrom pyconnectome.metrics.schcc import basic_network_analysis\nfrom pyconnectome.metrics.schcc import advanced_network_analysis\nfrom pyconnectome.metrics.schcc import create_graph\nfrom pyconnectome.utils.encoders import NetworkResultEncoder\nfrom pyconnectome.plotting.network import get_surface_parcellation_centroids\nfrom pyconnectome.plotting.network import plot_network\nfrom pyconnectome.plotting.network import dict2list\n\n# Pyfreesurfer import\nfrom pyfreesurfer import DEFAULT_FREESURFER_PATH\nfrom pyfreesurfer.utils.surftools import TriSurface\n\n\n# Parameters to keep trace\n__hopla__ = [\"runtime\", \"inputs\", \"outputs\"]\n\n\nDOC = \"\"\"\nNetwork Analysis: compute different features of a network.\n\nCommand example on the HCP data:\n\npython $HOME/git/pyconnectome/pyconnectome/scripts/pyconnectome_metrics \\\n    -s 100206 \\\n    -o /volatile/nsap/hcp/metrics \\\n    -m /neurospin/hcp/ANALYSIS/3T_mrtrix_reduced_connectome/mrtrix/100206/connectome_endvox.txt \\\n    -l /neurospin/hcp/ANALYSIS/3T_mrtrix_reduced_connectome/mrtrix/100206/labels.txt \\\n    -f /neurospin/hcp/ANALYSIS/3T_freesurfer/100206/T1w \\\n    -g \\\n    -i \\\n    -v 2\n\"\"\"\n\n\ndef is_file(filearg):\n    \"\"\" Type for argparse - checks that file exists but does not open.\n    \"\"\"\n    if not os.path.isfile(filearg):\n        raise argparse.ArgumentError(\n            \"The file '{0}' does not exist!\".format(filearg))\n    return filearg\n\n\ndef is_directory(dirarg):\n    \"\"\" Type for argparse - checks that directory exists.\n    \"\"\"\n    if not os.path.isdir(dirarg):\n        raise argparse.ArgumentError(\n            \"The directory '{0}' does not exist!\".format(dirarg))\n    return dirarg\n\n\ndef get_cmd_line_args():\n    \"\"\"\n    Create a command line argument parser and return a dict mapping\n    <argument name> -> <argument value>.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"python pyconnectome_metrics\",\n        description=textwrap.dedent(DOC),\n        formatter_class=RawTextHelpFormatter)\n\n    # Required arguments\n    required = parser.add_argument_group(\"required arguments\")\n    required.add_argument(\n        \"-s\", \"--subjectid\",\n        required=True, metavar=\"<id>\",\n        help=\"Subject identifier.\")\n    required.add_argument(\n        \"-o\", \"--outdir\",\n        required=True, metavar=\"<path>\", type=is_directory,\n        help=\"directory where to output.\")\n    required.add_argument(\n        \"-m\", \"--connectomefile\",\n        required=True, metavar=\"<file>\", type=is_file,\n        help=\"the connectome matrix in CSV format with white space sparators.\")\n    required.add_argument(\n        \"-l\", \"--labelfile\",\n        required=True, metavar=\"<file>\", type=is_file,\n        help=\"the connectome labels.\")\n\n    # Optional arguments\n    parser.add_argument(\n        \"-g\", dest=\"graphics\",\n        action=\"store_true\",\n        help=\"if activated compute quality controls.\")\n    parser.add_argument(\n        \"-i\", dest=\"interactive\",\n        action=\"store_true\",\n        help=\"if activated display an interactive windows.\")\n    parser.add_argument(\n        \"-p\", dest=\"snapnx\", action=\"store_true\",\n        help=\"if activated generate a snap of the network.\")\n    parser.add_argument(\n        \"-a\", dest=\"animatenx\",\n        action=\"store_true\",\n        help=\"if activated display animate the network.\")\n    parser.add_argument(\n        \"-f\", \"--fsdir\",\n        metavar=\"<path>\", type=is_directory,\n        help=\"the Freesurfer home directory.\")\n    parser.add_argument(\n        \"-e\", \"--erase\",\n        action=\"store_true\",\n        help=\"if activated, clean the subject folder.\")\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        type=int, choices=[0, 1, 2], default=0,\n        help=\"increase the verbosity level: 0 silent, [1, 2] verbose.\")\n\n    # Create a dict of arguments to pass to the 'main' function\n    args = parser.parse_args()\n    kwargs = vars(args)\n    verbose = kwargs.pop(\"verbose\")\n    if kwargs[\"fsdir\"] is None:\n        kwargs[\"fsdir\"] = DEFAULT_FREESURFER_PATH\n\n    return kwargs, verbose"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Parse the command line.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "inputs, verbose = get_cmd_line_args()\ntool = \"pyconnectome_metrics\"\ntimestamp = datetime.now().isoformat()\ntool_version = version\nnetworkx_version = networkx.__version__\nbct_version = bct.__version__\nparams = locals()\nruntime = dict([(name, params[name])\n               for name in (\"tool\", \"tool_version\", \"timestamp\",\n                            \"networkx_version\", \"bct_version\")])\noutputs = None\nif verbose > 0:\n    print(\"[info] Starting Network Analysis ...\")\n    print(\"[info] Runtime:\")\n    pprint(runtime)\n    print(\"[info] Inputs:\")\n    pprint(inputs)\nsubjectdir = os.path.join(inputs[\"outdir\"], inputs[\"subjectid\"])\nif inputs[\"erase\"] and os.path.isdir(subjectdir):\n    shutil.rmtree(subjectdir)\nif not os.path.isdir(subjectdir):\n    os.mkdir(subjectdir)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Read labels and remove unknown regions\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "fsl_inputs = False\nif inputs[\"connectomefile\"].endswith(\".dot\"):\n    fsl_inputs = True\n# FSL case: list of coords with label\nif fsl_inputs:\n    labels_array = numpy.loadtxt(inputs[\"labelfile\"])\n    connectome_labels = [\"{0}-{1}\".format(hemi, idx)\n                         for _, _, _, hemi, idx in labels_array]\n# Simple list with region names\nelse:\n    connectome_labels = [\n        l.rstrip(\"\\n\") for l in open(inputs[\"labelfile\"]).readlines()]\n    try:\n        index = connectome_labels.index(\"Unknown\")\n        connectome_labels.pop(index)\n        connectome = numpy.delete(connectome, index, axis=0)\n        connectome = numpy.delete(connectome, index, axis=1)\n    except:\n        pass\nif verbose > 0:\n    print(\"[info] Processing connectome with {0} labels...\".format(\n        len(connectome_labels)))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Read/symmetrize the connectome and remove loops\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# FSL case: not a connectome matrix yet\nif fsl_inputs:\n    matrix_size = len(connectome_labels)\n    connectome = numpy.zeros((matrix_size, matrix_size), dtype=numpy.single)\n    with open(inputs[\"connectomefile\"]) as dotfile:\n        for line in dotfile:\n            split = line.strip().split()\n            idx1, idx2 = map(int, split[:2])\n            nb_connections = float(split[2])\n            connectome[idx1 - 1, idx2 - 1] = nb_connections\n# A connectome matrix is provided\nelse:\n    connectome = []\n    with open(inputs[\"connectomefile\"], \"rt\") as csvfile:\n        reader = csv.reader(csvfile, delimiter=\" \")\n        for row in reader:\n            connectome.append(row)\n    connectome = numpy.asarray(connectome).astype(numpy.single)\n    connectome += connectome.T\nfor i in range(connectome.shape[0]):\n    connectome[i, i] = 0\nif verbose > 0:\n    print(\"[info] Processing connectome with shape {0}...\".format(\n        connectome.shape))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Generate a graph\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "graph = create_graph(connectome, connectome_labels)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Start basic and advanced analysis\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "outdir = None\nif inputs[\"graphics\"]:\n    outdir = subjectdir\nbasic_network_features, basic_snapfiles = basic_network_analysis(\n    graph, outdir=outdir)\nadvanced_network_features, advanced_snapfiles  = advanced_network_analysis(\n    graph, kstep=1, sstep=600., outdir=outdir)\nnetwork_features = copy.deepcopy(basic_network_features)\nnetwork_features.update(advanced_network_features)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Save result\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "network_features_file = os.path.join(subjectdir, \"network_features.json\")\nwith open(network_features_file, \"wt\") as open_file:\n    json.dump(network_features, open_file, sort_keys=True, check_circular=True,\n              indent=4, cls=NetworkResultEncoder)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Load the FreeSurfer parcellations\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"graphics\"]:\n    rh_white = os.path.join(inputs[\"fsdir\"], inputs[\"subjectid\"], \"surf\",\n                            \"rh.white\")\n    rh_annot = os.path.join(inputs[\"fsdir\"], inputs[\"subjectid\"], \"label\",\n                            \"rh.aparc.annot\")\n    lh_white = os.path.join(inputs[\"fsdir\"], inputs[\"subjectid\"], \"surf\",\n                            \"lh.white\")\n    lh_annot = os.path.join(inputs[\"fsdir\"], inputs[\"subjectid\"], \"label\",\n                            \"lh.aparc.annot\")\n    lh_surf = TriSurface.load(lh_white, annotfile=lh_annot)\n    rh_surf = TriSurface.load(rh_white, annotfile=rh_annot)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Render the network\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"graphics\"]:\n    centroids = get_surface_parcellation_centroids(\n        lh_surf, rh_surf, connectome_labels)\n    nodes = centroids.values()\n    edges = graph.edges()\n    edge_weights = [elem[2][\"weight\"] for elem in graph.edges(data=True)]\n    weights = numpy.asarray(dict2list(network_features[\"strengths\"]))\n    plot_network(nodes, connectome_labels, weights=weights, edges=edges,\n                 weight_node_by_color=True, weight_node_by_size=False,\n                 edge_weights=edge_weights, weight_edge_by_color=True,\n                 weight_edge_by_size=True, animate=inputs[\"animatenx\"],\n                 snap=inputs[\"snapnx\"], interactive=inputs[\"interactive\"],\n                 outdir=subjectdir, actor_ang=(90, 180, 180))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Update the outputs and save them and the inputs in a 'logs' directory.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "logdir = os.path.join(subjectdir, \"logs\")\nif not os.path.isdir(logdir):\n    os.mkdir(logdir)\nparams = locals()\noutputs = dict([(name, params[name])\n                for name in (\"network_features_file\", \"basic_snapfiles\",\n                             \"advanced_snapfiles\")])\nfor name, final_struct in [(\"inputs\", inputs), (\"outputs\", outputs),\n                           (\"runtime\", runtime)]:\n    log_file = os.path.join(logdir, \"{0}.json\".format(name))\n    with open(log_file, \"wt\") as open_file:\n        json.dump(final_struct, open_file, sort_keys=True, check_circular=True,\n                  indent=4)\nif verbose > 1:\n    print(\"[info] Outputs:\")\n    pprint(outputs)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}