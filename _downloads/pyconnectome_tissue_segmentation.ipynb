{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nPyconnectome Tissue Segmentation\n================================\n\nExample automatically generated from package script.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# System import\nfrom __future__ import print_function\nimport argparse\nimport os\nimport shutil\nfrom datetime import datetime\nimport json\nfrom pprint import pprint\nimport textwrap\nfrom argparse import RawTextHelpFormatter\n\n# Bredala import\ntry:\n    import bredala\n    bredala.USE_PROFILER = False\n    bredala.register(\"pyconnectome.utils.segtools\",\n                     names=[\"bet2\", \"fast\", \"robustfov\"])\n    bredala.register(\"pydcmio.plotting.slicer\",\n                     names=[\"mosaic\"])\nexcept:\n    pass\n\n# Package import\nfrom pyconnectome import __version__ as version\nfrom pyconnectome import DEFAULT_FSL_PATH\nfrom pyconnectome.wrapper import FSLWrapper\nfrom pyconnectome.utils.segtools import bet2\nfrom pyconnectome.utils.segtools import fast\nfrom pyconnectome.utils.segtools import robustfov\n\n# Third party import\nimport numpy\nfrom pydcmio.plotting.slicer import mosaic\n\n\n# Parameters to keep trace\n__hopla__ = [\"runtime\", \"inputs\", \"outputs\"]\n\n\n# Script documentation\nDOC = \"\"\"\nFSL tissue segmentation\n\nTissue segmentation with FSL FAST.\n\nCommand example for T1 to atlas affine registration with cropping on\nthe Metastasis data:\n\npython $HOME/git/pyconnectome/pyconnectome/scripts/pyconnectome_tissue_segmentation \\\n    -o /volatile/nsap/recalage_cathy/segmentation \\\n    -s 585521174283 \\\n    -i /volatile/nsap/recalage_cathy/results/585521174283/brain.nii.gz \\\n    -S \\\n    -v 2\n\"\"\"\n\n\ndef is_file(filearg):\n    \"\"\" Type for argparse - checks that file exists but does not open.\n    \"\"\"\n    if not os.path.isfile(filearg):\n        raise argparse.ArgumentError(\n            \"The file '{0}' does not exist!\".format(filearg))\n    return filearg\n\n\ndef is_directory(dirarg):\n    \"\"\" Type for argparse - checks that directory exists.\n    \"\"\"\n    if not os.path.isdir(dirarg):\n        raise argparse.ArgumentError(\n            \"The directory '{0}' does not exist!\".format(dirarg))\n    return dirarg\n\n\ndef get_cmd_line_args():\n    \"\"\"\n    Create a command line argument parser and return a dict mapping\n    <argument name> -> <argument value>.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"pyconnectome_tissue_segmentation\",\n        description=textwrap.dedent(DOC),\n        formatter_class=RawTextHelpFormatter)\n\n    # Required arguments\n    required = parser.add_argument_group(\"required arguments\")\n    required.add_argument(\n        \"-o\", \"--outdir\",\n        required=True, metavar=\"<path>\", type=is_directory,\n        help=\"the analysis output directory where <outdir>/<sid> will be \"\n             \"generated.\")\n    required.add_argument(\n        \"-s\", \"--sid\",\n        required=True,\n        help=\"the subject identifier.\")\n    required.add_argument(\n        \"-i\", \"--inputfile\",\n        required=True, type=is_file,\n        help=\"the input MRI volume to be segmented.\")\n\n    # Optional arguments\n    parser.add_argument(\n        \"-S\", \"--dosnap\",\n        action=\"store_true\",\n        help=\"if activated, generate QC snaps.\")\n    parser.add_argument(\n        \"-T\", \"--intype\",\n        default=1, type=int, choices=range(1, 4),\n        help=\"type of the input image 1=T1, 2=T2, 3=PD\")\n    parser.add_argument(\n        \"-K\", \"--nbklass\",\n        default=3, type=int,\n        help=\"the number of class in the FAST modelization.\")\n    parser.add_argument(\n        \"-O\", \"--docrop\",\n        action=\"store_true\",\n        help=\"if set, reduce the FOC of the input image to remove lower head \"\n             \"and neck.\")\n    parser.add_argument(\n        \"-I\", \"--brainsize\",\n        type=int, default=170,\n        help=\"the brain size used during the cropping.\")\n    parser.add_argument(\n        \"-B\", \"--dobrain\",\n        action=\"store_true\",\n        help=\"if set, use the BET2 routine to segment the subject brain.\")\n    parser.add_argument(\n        \"-H\", \"--brainthr\", dest=\"brainthr\",\n        default=0.5, type=float,\n        help=\"the BET2 fractional intensity threshold (0->1).\")\n    parser.add_argument(\n        \"-F\", \"--fsl-sh\",\n        type=is_file, metavar=\"<path>\",\n        help=\"bash script initializing FSL's environment.\")\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        type=int, choices=[0, 1, 2], default=0,\n        help=\"increase the verbosity level: 0 silent, [1, 2] verbose.\")\n\n    # Create a dict of arguments to pass to the 'main' function\n    args = parser.parse_args()\n    kwargs = vars(args)\n    verbose = kwargs.pop(\"verbose\")\n    if kwargs[\"fsl_sh\"] is None:\n        kwargs[\"fsl_sh\"] = DEFAULT_FSL_PATH\n\n    return kwargs, verbose"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Parse the command line.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "inputs, verbose = get_cmd_line_args()\ntool = \"pyconnectome_tissue_segmentation\"\ntimestamp = datetime.now().isoformat()\ntool_version = version\nfsl_version = FSLWrapper([], shfile=inputs[\"fsl_sh\"]).version\nparams = locals()\nruntime = dict([(name, params[name])\n               for name in (\"tool\", \"tool_version\", \"fsl_version\",\n                            \"timestamp\")])\nsubjdir = os.path.join(inputs[\"outdir\"], inputs[\"sid\"])\nif not os.path.isdir(subjdir):\n    os.mkdir(subjdir)\noutputs = None\nsnaps = []\nif inputs[\"dosnap\"]:\n    snap_dir = os.path.join(subjdir, \"snap\")\n    if not os.path.isdir(snap_dir):\n        os.mkdir(snap_dir)\nif verbose > 0:\n    pprint(\"[info] Starting registration ...\")\n    pprint(\"[info] Runtime:\")\n    pprint(runtime)\n    pprint(\"[info] Inputs:\")\n    pprint(inputs)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 0: Remove lower head and neck.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"docrop\"]:\n    # Crop\n    basename = os.path.basename(inputs[\"inputfile\"])\n    crop_dir = os.path.join(subjdir, \"robustfov\")\n    if not os.path.isdir(crop_dir):\n        os.mkdir(crop_dir)\n    cropped_file = os.path.join(crop_dir, \"robustfov_\" + basename)\n    cropped_trf = os.path.join(\n        crop_dir, \"robustfov_\" + basename.split(\".\")[0] + \".txt\")\n    robustfov(\n        input_file=inputs[\"inputfile\"],\n        output_file=cropped_file,\n        brain_size=inputs[\"brainsize\"],\n        matrix_file=cropped_trf,\n        fsl_sh=inputs[\"fsl_sh\"])\n\n    # Restore orginial shape\n    cropped_und_file = os.path.join(crop_dir, \"robustfov_und_\" + basename)\n    cropped_und_file, _ = flirt(\n        in_file=cropped_file,\n        ref_file=inputs[\"inputfile\"],\n        out=cropped_und_file,\n        init=cropped_trf,\n        applyxfm=True,\n        verbose=verbose,\n        shfile=inputs[\"fsl_sh\"])\n\n    # Perform QC\n    if inputs[\"dosnap\"]:\n        snaps.append(mosaic(impath=cropped_file,\n                            title=\"robustfov\",\n                            outdir=snap_dir))\nelse:\n    cropped_file = inputs[\"inputfile\"]\n    cropped_trf = None"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 1: Brain extraction\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"dobrain\"]:\n    bet_dir = os.path.join(subjdir, \"bet\")\n    if not os.path.isdir(bet_dir):\n        os.mkdir(bet_dir)\n    (brain_file, mask_file, mesh_file, outline_file, inskull_mask_file,\n     inskull_mesh_file, outskull_mask_file, outskull_mesh_file,\n     outskin_mask_file, outskin_mesh_file, skull_mask_file) = bet2(\n        input_file=cropped_file,\n        output_fileroot=bet_dir,\n        outline=False,\n        mask=True,\n        skull=False,\n        nooutput=False,\n        f=inputs[\"brainthr\"],\n        g=0,\n        radius=None,\n        smooth=None,\n        c=None,\n        threshold=False,\n        mesh=False,\n        shfile=inputs[\"fsl_sh\"])\n    if inputs[\"dosnap\"]:\n        snaps.append(mosaic(impath=brain_file,\n                            title=\"bet\",\n                            outdir=snap_dir))\nelse:\n    mask_file, mesh_file, outline_file, inskull_mask_file = (None, ) * 4\n    nskull_mesh_file, outskull_mesh_file, outskin_mask_file = (None, ) * 3\n    skull_mask_file, outskin_mesh_file, outskull_mask_file = (None, ) * 3\n    brain_file =  cropped_file\nif verbose > 0:\n    print(\"[result] Brain image: {0}.\".format(brain_file))\n    print(\"[result] Brain mask image: {0}.\".format(mask_file))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 2: Tissue segmentation and spatial intensity variations correction.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "fast_dir = os.path.join(subjdir, \"fast\")\nif not os.path.isdir(fast_dir):\n    os.mkdir(fast_dir)\nfast_fileroot = os.path.join(\n    fast_dir, os.path.basename(inputs[\"inputfile\"]).split(\".\")[0])\ntpm, tsm, segmentation_anatfile, bias_anatfile, biascorrected_anatfile = fast(\n    input_file=brain_file,\n    out_fileroot=fast_fileroot,\n    klass=inputs[\"nbklass\"],\n    im_type=inputs[\"intype\"],\n    segments=True,\n    bias_field=True,\n    bias_corrected_im=True,\n    probabilities=True,\n    shfile=inputs[\"fsl_sh\"])\nif inputs[\"dosnap\"]:\n    snaps.append(mosaic(impath=segmentation_anatfile,\n                        title=\"fast_segmentation\",\n                        outdir=snap_dir))\nif verbose > 0:\n    print(\"[result] Antomical tissues: {0}.\".format(segmentation_anatfile))\n    print(\"[result] Antomical bias field: {0}.\".format(bias_anatfile))\n    print(\"[result] Antomical bias corrected: {0}.\".format(\n        biascorrected_anatfile))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Update the outputs and save them and the inputs in a 'logs' directory.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "logdir = os.path.join(subjdir, \"logs\")\nif not os.path.isdir(logdir):\n    os.mkdir(logdir)\nparams = locals()\noutputs = dict([(name, params[name])\n               for name in (\"cropped_file\", \"cropped_trf\", \"tpm\", \"tsm\",\n                            \"segmentation_anatfile\", \"bias_anatfile\",\n                            \"biascorrected_anatfile\", \"brain_file\", \"mask_file\",\n                            \"snaps\")])\nfor name, final_struct in [(\"inputs\", inputs), (\"outputs\", outputs),\n                           (\"runtime\", runtime)]:\n    log_file = os.path.join(logdir, \"{0}.json\".format(name))\n    with open(log_file, \"wt\") as open_file:\n        json.dump(final_struct, open_file, sort_keys=True, check_circular=True,\n                  indent=4)\nif verbose > 1:\n    print(\"[info] Outputs:\")\n    pprint(outputs)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}