{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nPyconnectome Register\n=====================\n\nExample automatically generated from package script.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# System import\nfrom __future__ import print_function\nimport argparse\nimport os\nimport shutil\nfrom datetime import datetime\nimport json\nfrom pprint import pprint\nimport textwrap\nfrom argparse import RawTextHelpFormatter\n\n# Bredala import\ntry:\n    import bredala\n    bredala.USE_PROFILER = False\n    bredala.register(\"pyconnectome.utils.segtools\",\n                     names=[\"bet2\", \"fast\", \"robustfov\", \"roi_from_bbox\"])\n    bredala.register(\"pyconnectome.utils.filetools\",\n                     names=[\"fslreorient2std\"])\n    bredala.register(\"pyconnectome.utils.regtools\",\n                     names=[\"flirt\", \"fnirt\"])\n    bredala.register(\"pydcmio.plotting.slicer\",\n                     names=[\"mosaic\"])\nexcept:\n    pass\n\n# Package import\nfrom pyconnectome import __version__ as version\nfrom pyconnectome import DEFAULT_FSL_PATH\nfrom pyconnectome.wrapper import FSLWrapper\nfrom pyconnectome.utils.segtools import bet2\nfrom pyconnectome.utils.segtools import fast\nfrom pyconnectome.utils.segtools import robustfov\nfrom pyconnectome.utils.segtools import roi_from_bbox\nfrom pyconnectome.utils.regtools import flirt\nfrom pyconnectome.utils.regtools import fnirt\nfrom pyconnectome.utils.filetools import fslreorient2std\n\n# Third party import\nimport numpy\nfrom pydcmio.plotting.slicer import mosaic\n\n\n# Parameters to keep trace\n__hopla__ = [\"runtime\", \"inputs\", \"outputs\"]\n\n\n# Script documentation\nDOC = \"\"\"\nFSL registration\n\nRigid/affine or non linear registration with FSL using flirt and fnirt.\n\nCommand:\n\npython $HOME/git/pyfsl/pyconnectome/scripts/pyconnectome_register \\\n    -v 2 \\\n    -s test_fsl \\\n    -o /volatile/nsap/recalage_cathy/results \\\n    -i /volatile/nsap/recalage_cathy/T1W_gado.nii.gz \\\n    -r /usr/share/fsl/data/standard/MNI152_T1_1mm.nii.gz \\\n    -j /usr/share/fsl/data/standard/MNI152_T1_1mm_brain.nii.gz \\\n    -x /volatile/nsap/recalage_cathy/mask_lesion.nii.gz /volatile/nsap/recalage_cathy/mask_necrosis.nii.gz \\\n    -c /etc/fsl/5.0/fsl.sh \\\n    -k 3 \\\n    -t 1 \\\n    -f 0.45 \\\n    -b \\\n    -a normmi \\\n    -n \\\n    -d\n\n\nCommand example for T1 to atlas affine registration with cropping on\nthe Metastasis data:\n\npython $HOME/git/pyconnectome/pyconnectome/scripts/pyconnectome_register \\\n    -o /volatile/nsap/recalage_cathy/results \\\n    -s 585521174283 \\\n    -i /neurospin/radiomics/studies/metastasis/base/585521174283/anat/585521174283_enh-gado_T1w.nii.gz \\\n    -r /usr/share/fsl/data/standard/MNI152_T1_1mm.nii.gz \\\n    -O \\\n    -R 0 181 0 217 79 121 \\\n    -D \\\n    -Q /volatile/nsap/recalage_cathy/results/585521174283/brain.nii.gz \\\n    -S \\\n    -v 2\n\nCommand example for T1 to atlas non linear registration with cropping on\nthe Metastasis data:\n\npython $HOME/git/pyconnectome/pyconnectome/scripts/pyconnectome_register \\\n    -o /volatile/nsap/recalage_cathy/results/nl \\\n    -s 585521174283 \\\n    -i /neurospin/radiomics/studies/metastasis/base/585521174283/anat/585521174283_enh-gado_T1w.nii.gz \\\n    -r /usr/share/fsl/data/standard/MNI152_T1_1mm.nii.gz \\\n    -O \\\n    -N \\\n    -J /usr/share/fsl/data/standard/MNI152_T1_1mm_brain.nii.gz \\\n    -R 0 181 0 217 79 121 \\\n    -D \\\n    -Q /volatile/nsap/recalage_cathy/results/585521174283/brain.nii.gz \\\n    -S \\\n    -v 2\n\"\"\"\n\n\ndef is_file(filearg):\n    \"\"\" Type for argparse - checks that file exists but does not open.\n    \"\"\"\n    if not os.path.isfile(filearg):\n        raise argparse.ArgumentError(\n            \"The file '{0}' does not exist!\".format(filearg))\n    return filearg\n\n\ndef is_directory(dirarg):\n    \"\"\" Type for argparse - checks that directory exists.\n    \"\"\"\n    if not os.path.isdir(dirarg):\n        raise argparse.ArgumentError(\n            \"The directory '{0}' does not exist!\".format(dirarg))\n    return dirarg\n\n\ndef get_cmd_line_args():\n    \"\"\"\n    Create a command line argument parser and return a dict mapping\n    <argument name> -> <argument value>.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"pyconnectome_register\",\n        description=textwrap.dedent(DOC),\n        formatter_class=RawTextHelpFormatter)\n\n    # Required arguments\n    required = parser.add_argument_group(\"required arguments\")\n    required.add_argument(\n        \"-o\", \"--outdir\",\n        required=True, metavar=\"<path>\", type=is_directory,\n        help=\"the analysis output directory where <outdir>/<sid> will be \"\n             \"generated.\")\n    required.add_argument(\n        \"-s\", \"--sid\",\n        required=True,\n        help=\"the subject identifier.\")\n    required.add_argument(\n        \"-i\", \"--inputfile\",\n        required=True, type=is_file,\n        help=\"the input MRI volume to be registered.\")\n    required.add_argument(\n        \"-r\", \"--referencefile\", \n        required=True, type=is_file,\n        help=\"the template file used as a reference volume during the linear \"\n             \"registration.\")\n\n    # Optional arguments\n    parser.add_argument(\n        \"-C\", \"--nosearch\", \n        action=\"store_true\",\n        help=\"if set, perform no search to initializa the linear \"\n             \"optimization.\")\n    parser.add_argument(\n        \"-P\", \"--dof\",\n        type=int, default=12, choices=[6, 12],\n        help=\"the number of DOF in the linear registration.\")    \n    parser.add_argument(\n        \"-S\", \"--dosnap\",\n        action=\"store_true\",\n        help=\"if activated, generate QC snaps.\")\n    parser.add_argument(\n        \"-R\", \"--bbox\",\n        type=int, nargs=6, metavar=\"<INT>\",\n        help=\"a bounding box that will be wraped into the reference space.\")\n    parser.add_argument(\n        \"-E\", \"--erase\",\n        action=\"store_true\",\n        help=\"if activated, clean the result folder if already created.\")\n    parser.add_argument(\n        \"-X\", \"--extrafiles\",\n        type=is_file, nargs=\"*\",\n        help=\"list of files to apply transform to.\")\n    parser.add_argument(\n        \"-D\", \"--dotissues\",\n        action=\"store_true\",\n        help=\"if activated, segment the scan tissues with FAST and apply \"\n             \"spatial intensity variations correction.\")\n    parser.add_argument(\n        \"-T\", \"--intype\",\n        default=1, type=int, choices=range(1, 4),\n        help=\"type of the input image 1=T1, 2=T2, 3=PD\")\n    parser.add_argument(\n        \"-K\", \"--nbklass\",\n        default=3, type=int,\n        help=\"the number of class in the FAST modelization.\")\n    parser.add_argument(\n        \"-Z\", \"--doreorient\",\n        action=\"store_true\",\n        help=\"if set, use the FSL routine to reorient input images.\")\n    parser.add_argument(\n        \"-O\", \"--docrop\",\n        action=\"store_true\",\n        help=\"if set, reduce the FOV of the input image to remove lower head \"\n             \"and neck.\")\n    parser.add_argument(\n        \"-W\", \"--cropwho\",\n        default=\"moving\", choices=(\"moving\", \"reference\", \"both\"),\n        help=\"select which input images will be cropped.\")\n    parser.add_argument(\n        \"-I\", \"--brainsize\",\n        type=int, default=170,\n        help=\"the brain size used during the cropping.\")\n    parser.add_argument(\n        \"-B\", \"--dobrain\",\n        action=\"store_true\",\n        help=\"if set, use the BET2 routine to segment the subject brain.\")\n    parser.add_argument(\n        \"-Q\", \"--brain\",\n        type=is_file,\n        help=\"the subject brain.\")\n    parser.add_argument(\n        \"-H\", \"--brainthr\", dest=\"brainthr\",\n        default=0.5, type=float,\n        help=\"the BET2 fractional intensity threshold (0->1).\")\n    parser.add_argument(\n        \"-A\", \"--cost\",\n        default=\"normmi\",\n        choices=(\"mutualinfo\", \"corratio\", \"normcorr\", \"normmi\", \"leastsq\",\n                 \"labeldiff\", \"bbr\"),\n        help=\"the affine cost function type.\")\n    parser.add_argument(\n        \"-N\", \"--dononlinear\", \n        action=\"store_true\",\n        help=\"if set, use the FNIRT routine to align the subject brain to the \"\n             \"template with a non linear transformation.\")\n    parser.add_argument(\n        \"-J\", \"--referencebrainfile\",\n        type=is_file,\n        help=\"the template brain file used as a reference volume during the \"\n             \"non linear registration.\")\n    parser.add_argument(\n        \"-F\", \"--fsl-sh\",\n        type=is_file, metavar=\"<path>\",\n        help=\"bash script initializing FSL's environment.\")\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        type=int, choices=[0, 1, 2], default=0,\n        help=\"increase the verbosity level: 0 silent, [1, 2] verbose.\")\n\n    # Create a dict of arguments to pass to the 'main' function\n    args = parser.parse_args()\n    kwargs = vars(args)\n    verbose = kwargs.pop(\"verbose\")\n    if kwargs[\"fsl_sh\"] is None:\n        kwargs[\"fsl_sh\"] = DEFAULT_FSL_PATH\n\n    return kwargs, verbose"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Parse the command line.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "inputs, verbose = get_cmd_line_args()\ntool = \"pyconnectome_register\"\ntimestamp = datetime.now().isoformat()\ntool_version = version\nfsl_version = FSLWrapper([], shfile=inputs[\"fsl_sh\"]).version\nparams = locals()\nruntime = dict([(name, params[name])\n               for name in (\"tool\", \"tool_version\", \"fsl_version\",\n                            \"timestamp\")])\nsubjdir = os.path.join(inputs[\"outdir\"], inputs[\"sid\"])\nif inputs[\"erase\"] and os.path.isdir(subjdir):\n    shutil.rmtree(subjdir)\nif not os.path.isdir(subjdir):\n    os.mkdir(subjdir)\noutputs = None\nsnaps = []\nif inputs[\"dosnap\"]:\n    snap_dir = os.path.join(subjdir, \"snap\")\n    if not os.path.isdir(snap_dir):\n        os.mkdir(snap_dir)\nif verbose > 0:\n    pprint(\"[info] Starting registration ...\")\n    pprint(\"[info] Runtime:\")\n    pprint(runtime)\n    pprint(\"[info] Inputs:\")\n    pprint(inputs)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step -1: Reorient images.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"doreorient\"]:\n    reorient_dir = os.path.join(subjdir, \"reorient\")\n    if not os.path.isdir(reorient_dir):\n        os.mkdir(reorient_dir)\n    inputfile = os.path.join(\n        reorient_dir, os.path.basename(inputs[\"inputfile\"]))\n    fslreorient2std(\n        inputs[\"inputfile\"], inputfile, fslconfig=inputs[\"fsl_sh\"])\n    referencefile = os.path.join(\n        reorient_dir, os.path.basename(inputs[\"referencefile\"]))\n    fslreorient2std(\n        inputs[\"referencefile\"], referencefile, fslconfig=inputs[\"fsl_sh\"])\nelse:\n    inputfile = inputs[\"inputfile\"]\n    referencefile = inputs[\"referencefile\"]"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 0: Remove lower head and neck.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "crop_outputs = [None, None]\ncrop_outputs_und = [None, None]\ncrop_outputs_trf = [None, None]\nif inputs[\"docrop\"]:\n    \n    # Select step inputs\n    step_inputs = [None, None]\n    if inputs[\"cropwho\"] in (\"moving\", \"both\"):\n        step_inputs[0] = inputfile\n    if inputs[\"cropwho\"] in (\"reference\", \"both\"):\n        step_inputs[1] = referencefile\n\n    # Go through each input\n    for cnt, path in enumerate(step_inputs):\n\n        # Stop cas\n        if path is None:\n            continue\n\n        # Crop\n        basename = os.path.basename(path)\n        crop_dir = os.path.join(subjdir, \"robustfov\")\n        if not os.path.isdir(crop_dir):\n            os.mkdir(crop_dir)\n        cropped_file = os.path.join(crop_dir, \"robustfov_\" + basename)\n        cropped_trf = os.path.join(\n            crop_dir, \"robustfov_\" + basename.split(\".\")[0] + \".txt\")\n        robustfov(\n            input_file=path,\n            output_file=cropped_file,\n            brain_size=inputs[\"brainsize\"],\n            matrix_file=cropped_trf,\n            fsl_sh=inputs[\"fsl_sh\"])\n        crop_outputs[cnt] = cropped_file\n        crop_outputs_trf[cnt] = cropped_trf\n\n        # Restore orginial shape\n        cropped_und_file = os.path.join(crop_dir, \"robustfov_und_\" + basename)\n        cropped_und_file, _ = flirt(\n            in_file=cropped_file,\n            ref_file=path,\n            out=cropped_und_file,\n            init=cropped_trf,\n            applyxfm=True,\n            verbose=verbose,\n            shfile=inputs[\"fsl_sh\"])\n        crop_outputs[cnt] = cropped_und_file\n\n        # Perform QC\n        if inputs[\"dosnap\"]:\n            snaps.append(mosaic(impath=cropped_file,\n                                title=\"robustfov_{0}\".format(cnt),\n                                outdir=snap_dir))\nif crop_outputs[0] is not None:\n    cropped_moving_file = crop_outputs[0]\nelse:\n    cropped_moving_file = inputfile\nif crop_outputs[1] is not None:\n    cropped_reference_file = crop_outputs[1]\nelse:\n    cropped_reference_file = referencefile"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 1: Brain extraction\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"brain\"] is not None:\n    mask_file, mesh_file, outline_file, inskull_mask_file = (None, ) * 4\n    nskull_mesh_file, outskull_mesh_file, outskin_mask_file = (None, ) * 3\n    skull_mask_file, outskin_mesh_file, outskull_mask_file = (None, ) * 3\n    brain_file = inputs[\"brain\"]\n    # No BET, use full FOV\n    if inputs[\"docrop\"] and inputs[\"cropwho\"] in (\"moving\", \"both\"):\n        cropped_moving_file = crop_outputs_und[0]\nelif inputs[\"dobrain\"]:\n    bet_dir = os.path.join(subjdir, \"bet\")\n    if not os.path.isdir(bet_dir):\n        os.mkdir(bet_dir)\n    (brain_file, mask_file, mesh_file, outline_file, inskull_mask_file,\n     inskull_mesh_file, outskull_mask_file, outskull_mesh_file,\n     outskin_mask_file, outskin_mesh_file, skull_mask_file) = bet2(\n        input_file=cropped_moving_file,\n        output_fileroot=bet_dir,\n        outline=False,\n        mask=True,\n        skull=False,\n        nooutput=False,\n        f=inputs[\"brainthr\"],\n        g=0,\n        radius=None,\n        smooth=None,\n        c=None,\n        threshold=False,\n        mesh=False,\n        shfile=inputs[\"fsl_sh\"])\n    if inputs[\"dosnap\"]:\n        snaps.append(mosaic(impath=brain_file,\n                            title=\"bet\",\n                            outdir=snap_dir))\nelse:\n    mask_file, mesh_file, outline_file, inskull_mask_file = (None, ) * 4\n    nskull_mesh_file, outskull_mesh_file, outskin_mask_file = (None, ) * 3\n    skull_mask_file, outskin_mesh_file, outskull_mask_file = (None, ) * 3\n    brain_file =  cropped_moving_file\nif verbose > 0:\n    print(\"[result] Brain image: {0}.\".format(brain_file))\n    print(\"[result] Brain mask image: {0}.\".format(mask_file))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 2: Tissue segmentation and spatial intensity variations correction.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"dotissues\"]:\n    fast_dir = os.path.join(subjdir, \"fast\")\n    if not os.path.isdir(fast_dir):\n        os.mkdir(fast_dir)\n    fast_fileroot = os.path.join(\n        fast_dir, os.path.basename(inputs[\"inputfile\"]).split(\".\")[0])\n    tpm, tsm, segmentation_anatfile, bias_anatfile, biascorrected_anatfile = fast(\n        input_file=brain_file,\n        out_fileroot=fast_fileroot,\n        klass=inputs[\"nbklass\"],\n        im_type=inputs[\"intype\"],\n        segments=True,\n        bias_field=True,\n        bias_corrected_im=True,\n        probabilities=True,\n        shfile=inputs[\"fsl_sh\"])\n    if inputs[\"dosnap\"]:\n        snaps.append(mosaic(impath=segmentation_anatfile,\n                            title=\"fast_segmentation\",\n                            outdir=snap_dir))\nelse:\n    tpm, tsm, segmentation_anatfile, bias_anatfile = (None, None, None, None)\n    biascorrected_anatfile = brain_file\nif verbose > 0:\n    print(\"[result] Antomical tissues: {0}.\".format(segmentation_anatfile))\n    print(\"[result] Antomical bias field: {0}.\".format(bias_anatfile))\n    print(\"[result] Antomical bias corrected: {0}.\".format(\n        biascorrected_anatfile))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 3: Affine registration\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "basename = os.path.basename(biascorrected_anatfile).split(\".\")[0]\nflirt_dir = os.path.join(subjdir, \"flirt\")\nif not os.path.isdir(flirt_dir):\n    os.mkdir(flirt_dir)\naffine_file, affine_omat = flirt(\n    in_file=cropped_moving_file,\n    ref_file=cropped_reference_file,\n    omat=os.path.join(flirt_dir, \"flirt_{0}_to_template.txt\".format(basename)),\n    out=os.path.join(flirt_dir, \"flirt_{0}.nii.gz\".format(basename)),\n    init=None,\n    cost=inputs[\"cost\"],\n    usesqform=False,\n    displayinit=False,\n    anglerep=\"euler\",\n    bins=256,\n    interp=\"trilinear\",\n    dof=inputs[\"dof\"],\n    applyxfm=False,\n    applyisoxfm=None,\n    nosearch=inputs[\"nosearch\"],\n    verbose=verbose,\n    shfile=inputs[\"fsl_sh\"])\nif inputs[\"dosnap\"]:\n    snaps.append(mosaic(impath=cropped_reference_file,\n                        overlay=affine_file,\n                        title=\"affine_registration\",\n                        outdir=snap_dir))\nif verbose > 0:\n    print(\"[result] Affine: {0}.\".format(affine_file))\n    print(\"[result] Affine transformation: {0}.\".format(affine_omat))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 4: Non linear registration\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"dononlinear\"]:\n    fnirt_dir = os.path.join(subjdir, \"fnirt\")\n    if not os.path.isdir(fnirt_dir):\n        os.mkdir(fnirt_dir)\n    cout, iout, fout, jout, refout, intout, logout = fnirt(\n        in_file=brain_file,\n        ref_file=inputs[\"referencebrainfile\"],\n        affine_file=affine_omat,\n        outdir=fnirt_dir,\n        inmask_file=None,\n        verbose=verbose,\n        shfile=inputs[\"fsl_sh\"])\n    if inputs[\"dosnap\"]:\n        snaps.append(mosaic(impath=cropped_reference_file,\n                            overlay=iout,\n                            title=\"nonlinear_registration\",\n                            outdir=snap_dir))\nelse:\n    cout, iout, fout, jout, refout, intout, logout = (None, ) * 7"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 5: Create bounding box\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "if inputs[\"bbox\"] is not None:\n\n    # Create bbox\n    bbox_dir = os.path.join(subjdir, \"bbox\")\n    if not os.path.isdir(bbox_dir):\n        os.mkdir(bbox_dir)\n    bbox_file = os.path.join(bbox_dir, \"bbox.nii.gz\")\n    roi_from_bbox(\n        input_file=cropped_reference_file,\n        bbox=inputs[\"bbox\"],\n        output_file=bbox_file)\n\n    # Invert anat2dif transform\n    inv_affine_omat = os.path.join(\n        bbox_dir, \"flirt_template_to_{0}.txt\".format(basename))\n    m = numpy.loadtxt(affine_omat)\n    m_inv = numpy.linalg.inv(m)\n    numpy.savetxt(inv_affine_omat, m_inv)\n\n    # Send bbox to native space\n    native_bbox_file = os.path.join(bbox_dir, \"native_bbox.nii.gz\")\n    native_bbox_file, _ = flirt(\n        in_file=bbox_file,\n        ref_file=inputs[\"inputfile\"],\n        out=native_bbox_file,\n        init=inv_affine_omat,\n        applyxfm=True,\n        interp=\"nearestneighbour\",\n        verbose=verbose,\n        shfile=inputs[\"fsl_sh\"])\n\n    # Snap\n    if inputs[\"dosnap\"]:\n        snaps.append(mosaic(impath=inputs[\"inputfile\"],\n                            overlay=native_bbox_file,\n                            title=\"bbox native\",\n                            outdir=snap_dir))\n\nelse:\n    bbox_file = None\n    native_bbox_file = None"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Step 6: Apply deformation to extra files\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "extramnifiles = []\nif inputs[\"extrafiles\"] is not None:\n    extra_dir = os.path.join(subjdir, \"extra\")\n    if not os.path.isdir(extra_dir):\n        os.mkdir(extra_dir)\n    for path in inputs[\"extrafiles\"]:\n        if inputs[\"dononlinear\"]:\n            raise NotImplementedError(\n                \"Use applywarp -r MNI152_T1_1mm.nii -i myvolume.nii \"\n                \"-o myvolumeInMNI.nii -w warp_struct2mni.nii \"\n                \"--premat=func2struct.mat\")\n        else:\n            path_mni_file = os.path.join(extra_dir, os.path.basename(path))\n            path_mni_file, _ = flirt(\n                in_file=path,\n                ref_file=cropped_reference_file,\n                out=path_mni_file,\n                init=affine_omat,\n                applyxfm=True,\n                interp=\"spline\",\n                verbose=verbose,\n                shfile=inputs[\"fsl_sh\"])\n            extramnifiles.append(path_mni_file)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Update the outputs and save them and the inputs in a 'logs' directory.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "logdir = os.path.join(subjdir, \"logs\")\nif not os.path.isdir(logdir):\n    os.mkdir(logdir)\nparams = locals()\noutputs = dict([(name, params[name])\n               for name in (\"cropped_moving_file\", \"cropped_reference_file\",\n                            \"crop_outputs_trf\", \"tpm\", \"tsm\",\n                            \"segmentation_anatfile\", \"bias_anatfile\",\n                            \"biascorrected_anatfile\", \"brain_file\", \"mask_file\",\n                            \"affine_file\", \"affine_omat\", \"cout\", \"iout\",\n                            \"fout\", \"jout\", \"refout\", \"intout\", \"logout\",\n                            \"native_bbox_file\", \"bbox_file\", \"extramnifiles\",\n                            \"snaps\")])\nfor name, final_struct in [(\"inputs\", inputs), (\"outputs\", outputs),\n                           (\"runtime\", runtime)]:\n    log_file = os.path.join(logdir, \"{0}.json\".format(name))\n    with open(log_file, \"wt\") as open_file:\n        json.dump(final_struct, open_file, sort_keys=True, check_circular=True,\n                  indent=4)\nif verbose > 1:\n    print(\"[info] Outputs:\")\n    pprint(outputs)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}